<?xml version="1.0" encoding="UTF-8"?><xml><records><record><source-app name="Biblio" version="7.x">Drupal-Biblio</source-app><ref-type>10</ref-type><contributors><authors><author><style face="normal" font="default" size="100%">Despoina Chatzakou</style></author><author><style face="normal" font="default" size="100%">Nicolas Kourtellis</style></author><author><style face="normal" font="default" size="100%">Jeremy Blackburn</style></author><author><style face="normal" font="default" size="100%">Emiliano De Cristofaro</style></author><author><style face="normal" font="default" size="100%">Gianluca Stringhini</style></author><author><style face="normal" font="default" size="100%">Athena Vakali</style></author></authors></contributors><titles><title><style face="normal" font="default" size="100%">Detecting Aggressors and Bullies on Twitter</style></title><secondary-title><style face="normal" font="default" size="100%">Proceedings of the 26th International Conference on World Wide Web Companion</style></secondary-title><tertiary-title><style face="normal" font="default" size="100%">WWW '17 Companion</style></tertiary-title></titles><keywords><keyword><style  face="normal" font="default" size="100%">crowdsourcing</style></keyword><keyword><style  face="normal" font="default" size="100%">cyber-aggression</style></keyword><keyword><style  face="normal" font="default" size="100%">cyberbullying</style></keyword><keyword><style  face="normal" font="default" size="100%">Twitter</style></keyword></keywords><dates><year><style  face="normal" font="default" size="100%">2017</style></year></dates><urls><web-urls><url><style face="normal" font="default" size="100%">http://dl.acm.org/citation.cfm?id=3054211</style></url></web-urls></urls><publisher><style face="normal" font="default" size="100%">ACM</style></publisher><pub-location><style face="normal" font="default" size="100%">Perth, Australia</style></pub-location><pages><style face="normal" font="default" size="100%">767--768</style></pages><abstract><style face="normal" font="default" size="100%">&lt;p&gt;Online social networks constitute an integral part of people's every day social activity and the existence of aggressive and bullying phenomena in such spaces is inevitable. In this work, we analyze user behavior on Twitter in an effort to detect cyberbullies and cuber-aggressors by considering specific attributes of their online activity using machine learning classifiers.&lt;/p&gt;
</style></abstract></record><record><source-app name="Biblio" version="7.x">Drupal-Biblio</source-app><ref-type>10</ref-type><contributors><authors><author><style face="normal" font="default" size="100%">Despoina Chatzakou</style></author><author><style face="normal" font="default" size="100%">Nicolas Kourtellis</style></author><author><style face="normal" font="default" size="100%">Jeremy Blackburn</style></author><author><style face="normal" font="default" size="100%">Emiliano De Cristofaro</style></author><author><style face="normal" font="default" size="100%">Gianluca Stringhini</style></author><author><style face="normal" font="default" size="100%">Athena Vakali</style></author></authors></contributors><titles><title><style face="normal" font="default" size="100%">Hate is not Binary: Studying Abusive Behavior of #GamerGate on Twitter</style></title><tertiary-title><style face="normal" font="default" size="100%">HT '17</style></tertiary-title></titles><dates><year><style  face="normal" font="default" size="100%">2017</style></year></dates><publisher><style face="normal" font="default" size="100%">ACM</style></publisher><pub-location><style face="normal" font="default" size="100%">Prague, Czech Republic</style></pub-location><language><style face="normal" font="default" size="100%">eng</style></language><abstract><style face="normal" font="default" size="100%">&lt;p&gt;Over the past few years, online bullying and aggression have become increasingly prominent, and manifested in many different forms on social media. However, there is little work analyzing the characteristics of abusive users and what distinguishes them from typical social media users. In this paper, we start addressing this gap by analyzing tweets containing a great amount of abusiveness. We focus on a Twitter dataset revolving around the Gamergate controversy, which led to many incidents of cyberbullying and cyberaggression on various gaming and social media platforms. We study the properties of the users tweeting about Gamergate, the content they post, and the differences in their behavior compared to typical Twitter users.&lt;/p&gt;

&lt;p&gt;We find that while their tweets are often seemingly about aggressive and hateful subjects, ``Gamergaters'' do not exhibit common expressions of online anger, and in fact primarily differ from typical users in that their tweets are less joyful. They are also more engaged than typical Twitter users, which is an indication as to how and why this controversy is still ongoing. Surprisingly, we find that Gamergaters are less likely to be suspended by Twitter, thus we analyze their properties to identify differences from typical users and what may have led to their suspension. We perform an unsupervised machine learning analysis to detect clusters of users who, though currently active, could be considered for suspension since they exhibit similar behaviors with suspended users. Finally, we confirm the usefulness of our analyzed features by emulating the Twitter suspension mechanism with a supervised learning method, achieving very good precision and recall.&lt;/p&gt;
</style></abstract></record><record><source-app name="Biblio" version="7.x">Drupal-Biblio</source-app><ref-type>10</ref-type><contributors><authors><author><style face="normal" font="default" size="100%">Despoina Chatzakou</style></author><author><style face="normal" font="default" size="100%">Nicolas Kourtellis</style></author><author><style face="normal" font="default" size="100%">Jeremy Blackburn</style></author><author><style face="normal" font="default" size="100%">Emiliano De Cristofaro</style></author><author><style face="normal" font="default" size="100%">Gianluca Stringhini</style></author><author><style face="normal" font="default" size="100%">Athena Vakali</style></author></authors></contributors><titles><title><style face="normal" font="default" size="100%">Mean Birds: Detecting Aggression and Bullying on Twitter</style></title><tertiary-title><style face="normal" font="default" size="100%">WebSci '17</style></tertiary-title></titles><dates><year><style  face="normal" font="default" size="100%">2017</style></year></dates><urls><web-urls><url><style face="normal" font="default" size="100%">https://arxiv.org/abs/1702.06877</style></url></web-urls></urls><publisher><style face="normal" font="default" size="100%">ACM</style></publisher><pub-location><style face="normal" font="default" size="100%">Troy, NY, USA</style></pub-location><language><style face="normal" font="default" size="100%">eng</style></language><abstract><style face="normal" font="default" size="100%">&lt;p&gt;In recent years, bullying and aggression against users on social media have grown significantly, causing serious consequences to victims of all demographics. In particular, cyberbullying affects more than half of young social media users worldwide, and has also led to teenage suicides, prompted by prolonged and/or coordinated digital harassment. Nonetheless, tools and technologies for understanding and mitigating it are scarce and mostly ineffective. In this paper, we present a principled and scalable approach to detect bullying and aggressive behavior on Twitter. We propose a robust methodology for extracting text, user, and network-based attributes, studying the properties of cyberbullies and aggressors, and what features distinguish them from regular users. We find that bully users post less, participate in fewer online communities, and are less popular than normal users, while aggressors are quite popular and tend to include more negativity in their posts. We evaluate our methodology using a corpus of 1.6M tweets posted over 3 months, and show that machine learning classification algorithms can accurately detect users exhibiting bullying and aggressive behavior, achieving over 90% AUC.&lt;/p&gt;
</style></abstract></record><record><source-app name="Biblio" version="7.x">Drupal-Biblio</source-app><ref-type>10</ref-type><contributors><authors><author><style face="normal" font="default" size="100%">Despoina Chatzakou</style></author><author><style face="normal" font="default" size="100%">Nicolas Kourtellis</style></author><author><style face="normal" font="default" size="100%">Jeremy Blackburn</style></author><author><style face="normal" font="default" size="100%">Emiliano De Cristofaro</style></author><author><style face="normal" font="default" size="100%">Gianluca Stringhini</style></author><author><style face="normal" font="default" size="100%">Athena Vakali</style></author></authors></contributors><titles><title><style face="normal" font="default" size="100%">Measuring #GamerGate: A Tale of Hate, Sexism, and Bullying</style></title><secondary-title><style face="normal" font="default" size="100%">Proceedings of the 26th International Conference on World Wide Web Companion</style></secondary-title><tertiary-title><style face="normal" font="default" size="100%">WWW '17 Companion</style></tertiary-title></titles><dates><year><style  face="normal" font="default" size="100%">2017</style></year></dates><urls><web-urls><url><style face="normal" font="default" size="100%">http://dl.acm.org/citation.cfm?id=3053890</style></url></web-urls></urls><publisher><style face="normal" font="default" size="100%">ACM</style></publisher><pub-location><style face="normal" font="default" size="100%">Perth, Australia</style></pub-location><pages><style face="normal" font="default" size="100%">1285-1290</style></pages><language><style face="normal" font="default" size="100%">eng</style></language><abstract><style face="normal" font="default" size="100%">&lt;p&gt;Over the past few years, online aggression and abusive behaviors have occurred in many different forms and on a variety of platforms. In extreme cases, these incidents have evolved into hate, discrimination, and bullying, and even materialized into real-world threats and attacks against individuals or groups. In this paper, we study the Gamergate controversy. Started in August 2014 in the online gaming world, it quickly spread across various social networking platforms, ultimately leading to many incidents of cyberbullying and cyberaggression. We focus on Twitter, presenting a measurement study of a dataset of 340k unique users and 1.6M tweets to study the properties of these users, the content they post, and how they differ from random Twitter users. We find that users involved in this &quot;Twitter war&quot; tend to have more friends and followers, are generally more engaged and post tweets with negative sentiment, less joy, and more hate than random users. We also perform preliminary measurements on how the Twitter suspension mechanism deals with such abusive behaviors. While we focus on Gamergate, our methodology to collect and analyze tweets related to aggressive and bullying activities is of independent interest.&lt;/p&gt;
</style></abstract></record></records></xml>